#!/usr/bin/env python3
"""
é›†æˆæ¨è«–è…³æœ¬ v4.0

æ”¯æ´å¤šç¨®é›†æˆç­–ç•¥ï¼šå¹³å‡ã€åŠ æ¬Šå¹³å‡ã€éšå±¤å¼é›†æˆã€‚

ä½¿ç”¨æ–¹å¼:
    # ä½¿ç”¨ ensemble.yaml é…ç½®
    python -m src.ensemble_v2
    
    # æŒ‡å®šç­–ç•¥
    python -m src.ensemble_v2 --strategy hierarchical
    
    # åªä½¿ç”¨éƒ¨åˆ†æ¨¡å‹
    python -m src.ensemble_v2 --models dino_vitl14 dino_vitl14_deep convnext_base
"""

import argparse
import os
from pathlib import Path
from typing import Dict, Any, List, Optional

import numpy as np
import pandas as pd
from tqdm import tqdm

from .utils.config import load_config


# ============================================================================
# é›†æˆç­–ç•¥
# ============================================================================

def ensemble_average(prob_dict: Dict[str, np.ndarray]) -> np.ndarray:
    """ç°¡å–®å¹³å‡"""
    probs = list(prob_dict.values())
    return np.mean(probs, axis=0)


def ensemble_weighted_average(
    prob_dict: Dict[str, np.ndarray], 
    weights: Dict[str, float]
) -> np.ndarray:
    """åŠ æ¬Šå¹³å‡"""
    result = np.zeros_like(list(prob_dict.values())[0])
    total_weight = 0
    
    for name, prob in prob_dict.items():
        weight = weights.get(name, 1.0)
        result += prob * weight
        total_weight += weight
    
    return result / total_weight


def ensemble_hierarchical(
    prob_dict: Dict[str, np.ndarray],
    groups: List[Dict],
) -> np.ndarray:
    """
    éšå±¤å¼é›†æˆ
    
    å…ˆåœ¨å„é™£ç‡Ÿå…§éƒ¨å¹³å‡ï¼Œå†ç”¨æ¬Šé‡åˆä½µé™£ç‡Ÿ
    """
    result = np.zeros_like(list(prob_dict.values())[0])
    total_weight = 0
    
    for group in groups:
        group_name = group['name']
        group_weight = group['weight']
        group_models = group['models']
        
        # è¨ˆç®—é™£ç‡Ÿå…§éƒ¨å¹³å‡
        group_probs = []
        for model_name in group_models:
            if model_name in prob_dict:
                group_probs.append(prob_dict[model_name])
            else:
                print(f"âš ï¸ Model {model_name} not found in predictions, skipping")
        
        if group_probs:
            group_avg = np.mean(group_probs, axis=0)
            result += group_avg * group_weight
            total_weight += group_weight
            print(f"   {group_name}: {len(group_probs)} models, weight {group_weight}")
    
    return result / total_weight if total_weight > 0 else result


def ensemble_vote(prob_dict: Dict[str, np.ndarray], threshold: float = 0.5) -> np.ndarray:
    """Soft voting (åŸºæ–¼å¤šæ•¸æ±º)"""
    probs = list(prob_dict.values())
    votes = np.array([p > threshold for p in probs])
    return votes.mean(axis=0)


# ============================================================================
# ä¸»è¦å‡½æ•¸
# ============================================================================

def load_predictions(output_dir: str, model_names: List[str], use_tta: bool = True) -> Dict[str, np.ndarray]:
    """è¼‰å…¥å„æ¨¡å‹çš„é æ¸¬"""
    prob_dict = {}
    filenames = None
    
    suffix = '_tta' if use_tta else ''
    
    for model_name in model_names:
        prob_path = Path(output_dir) / model_name / f'predictions_probs{suffix}.csv'
        
        if not prob_path.exists():
            # å˜—è©¦ä¸å¸¶ TTA çš„ç‰ˆæœ¬
            prob_path = Path(output_dir) / model_name / 'predictions_probs.csv'
        
        if prob_path.exists():
            df = pd.read_csv(prob_path)
            df['filename'] = df['filename'].astype(str)
            df = df.sort_values('filename')
            
            if filenames is None:
                filenames = df['filename'].tolist()
            
            prob_dict[model_name] = df['prob'].values
            print(f"âœ… Loaded {model_name}: {len(df)} predictions")
        else:
            print(f"âš ï¸ Not found: {prob_path}")
    
    return prob_dict, filenames


def run_ensemble(
    config_path: str = "configs/ensemble.yaml",
    strategy: Optional[str] = None,
    model_names: Optional[List[str]] = None,
    use_tta: bool = True,
    thresholds: List[float] = [0.3, 0.4, 0.5, 0.6],
):
    """
    åŸ·è¡Œé›†æˆ
    
    Args:
        config_path: é›†æˆé…ç½®è·¯å¾‘
        strategy: é›†æˆç­–ç•¥ (è¦†è“‹é…ç½®)
        model_names: è¦é›†æˆçš„æ¨¡å‹åˆ—è¡¨ (è¦†è“‹é…ç½®)
        use_tta: æ˜¯å¦ä½¿ç”¨ TTA é æ¸¬
        thresholds: è¦ç”Ÿæˆçš„é–¾å€¼åˆ—è¡¨
    """
    # è¼‰å…¥é…ç½®
    config = load_config(config_path)
    ensemble_config = config.get('ensemble', {})
    
    # ç¢ºå®šç­–ç•¥
    if strategy is None:
        strategy = ensemble_config.get('strategy', 'average')
    
    print("\n" + "=" * 60)
    print(f"ğŸ”— Ensemble with strategy: {strategy}")
    print("=" * 60)
    
    # ç¢ºå®šè¦ä½¿ç”¨çš„æ¨¡å‹
    if model_names is None:
        if strategy == 'hierarchical':
            groups = ensemble_config.get('hierarchical', {}).get('groups', [])
            model_names = []
            for group in groups:
                model_names.extend(group['models'])
        elif strategy == 'weighted_average':
            models_config = ensemble_config.get('weighted_average', {}).get('models', [])
            model_names = [m['name'] for m in models_config]
        else:
            # å¾è¼¸å‡ºç›®éŒ„è‡ªå‹•åµæ¸¬
            output_dir = config.get('output', {}).get('save_dir', './outputs')
            model_names = [d.name for d in Path(output_dir).iterdir() 
                          if d.is_dir() and (d / 'predictions_probs.csv').exists()]
    
    print(f"ğŸ“Š Models to ensemble: {model_names}")
    
    # è¼‰å…¥é æ¸¬
    output_dir = config.get('output', {}).get('save_dir', './outputs')
    prob_dict, filenames = load_predictions(output_dir, model_names, use_tta)
    
    if not prob_dict:
        print("âŒ No predictions found!")
        return
    
    print(f"\nğŸ“Š Successfully loaded {len(prob_dict)} models")
    
    # åŸ·è¡Œé›†æˆ
    if strategy == 'average':
        final_probs = ensemble_average(prob_dict)
        
    elif strategy == 'weighted_average':
        models_config = ensemble_config.get('weighted_average', {}).get('models', [])
        weights = {m['name']: m['weight'] for m in models_config}
        final_probs = ensemble_weighted_average(prob_dict, weights)
        
    elif strategy == 'hierarchical':
        groups = ensemble_config.get('hierarchical', {}).get('groups', [])
        print("\nğŸ“Š Hierarchical ensemble:")
        final_probs = ensemble_hierarchical(prob_dict, groups)
        
    elif strategy == 'vote':
        final_probs = ensemble_vote(prob_dict)
        
    else:
        raise ValueError(f"Unknown strategy: {strategy}")
    
    # è¼¸å‡ºç›®éŒ„
    ensemble_output_dir = Path(output_dir) / 'ensemble'
    ensemble_output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜æ©Ÿç‡
    suffix = '_tta' if use_tta else ''
    prob_df = pd.DataFrame({
        'filename': filenames,
        'prob': final_probs
    })
    prob_path = ensemble_output_dir / f'ensemble_probs{suffix}.csv'
    prob_df.to_csv(prob_path, index=False)
    print(f"\nâœ… Ensemble probabilities saved to {prob_path}")
    
    # çµ±è¨ˆ
    print(f"\nğŸ“Š Ensemble Probability Statistics:")
    print(f"   Mean: {final_probs.mean():.4f}")
    print(f"   Std: {final_probs.std():.4f}")
    print(f"   Median: {np.median(final_probs):.4f}")
    
    # ç”Ÿæˆä¸åŒé–¾å€¼çš„ submission
    print(f"\nğŸ“Š Generating submissions...")
    
    for t in thresholds:
        labels = ['fake' if p > t else 'real' for p in final_probs]
        t_df = pd.DataFrame({'filename': filenames, 'label': labels})
        t_path = ensemble_output_dir / f'ensemble_submission{suffix}_t{int(t*10)}.csv'
        t_df.to_csv(t_path, index=False)
        fake_count = labels.count('fake')
        print(f"   t={t}: Fake={fake_count} ({fake_count/len(labels)*100:.1f}%) -> {t_path}")
    
    # ä½¿ç”¨ median ä½œç‚ºé è¨­
    median_threshold = np.median(final_probs)
    labels = ['fake' if p > median_threshold else 'real' for p in final_probs]
    submission_df = pd.DataFrame({'filename': filenames, 'label': labels})
    submission_path = ensemble_output_dir / f'ensemble_submission{suffix}.csv'
    submission_df.to_csv(submission_path, index=False)
    
    fake_count = labels.count('fake')
    print(f"\nğŸ† Final ensemble submission (median threshold {median_threshold:.4f}):")
    print(f"   Fake: {fake_count} ({fake_count/len(labels)*100:.1f}%)")
    print(f"   Real: {len(labels)-fake_count} ({(len(labels)-fake_count)/len(labels)*100:.1f}%)")
    print(f"   Saved to: {submission_path}")
    
    # è¨ˆç®—æ¨¡å‹ç›¸é—œæ€§
    if len(prob_dict) > 1:
        print("\nğŸ“Š Model Correlation Matrix:")
        df_corr = pd.DataFrame(prob_dict)
        corr_matrix = df_corr.corr()
        print(corr_matrix.to_string())
        
        # ä¿å­˜ç›¸é—œæ€§
        corr_path = ensemble_output_dir / 'model_correlation.csv'
        corr_matrix.to_csv(corr_path)
    
    return filenames, final_probs


# ============================================================================
# ä¸»ç¨‹å¼
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description='Deepfake Detection Ensemble v4.0')
    
    parser.add_argument('--config', type=str, default='configs/ensemble.yaml',
                        help='Path to ensemble config')
    parser.add_argument('--strategy', type=str, default=None,
                        choices=['average', 'weighted_average', 'hierarchical', 'vote'],
                        help='Ensemble strategy (overrides config)')
    parser.add_argument('--models', type=str, nargs='+', default=None,
                        help='Models to ensemble (overrides config)')
    parser.add_argument('--no-tta', action='store_true',
                        help='Use non-TTA predictions')
    parser.add_argument('--thresholds', type=float, nargs='+',
                        default=[0.3, 0.4, 0.5, 0.6],
                        help='Thresholds to generate submissions')
    
    args = parser.parse_args()
    
    run_ensemble(
        config_path=args.config,
        strategy=args.strategy,
        model_names=args.models,
        use_tta=not args.no_tta,
        thresholds=args.thresholds,
    )


if __name__ == '__main__':
    main()
