"""
å¤šæ¨¡å‹è¨“ç·´è…³æœ¬ v3.3

æ”¯æ´å¤šç¨® backbone æ¶æ§‹çš„å®Œæ•´è¨“ç·´æµç¨‹ï¼š
- å‹•æ…‹æ¨¡å‹è¼‰å…¥ï¼ˆEfficientNet-B0~B4 ç­‰ï¼‰
- åˆ†å±¤å­¸ç¿’ç‡ï¼ˆbackbone å’Œ classifier ä½¿ç”¨ä¸åŒå­¸ç¿’ç‡ï¼‰
- å‡çµ backbone é¸é …ï¼ˆé¡ä¼¼ CLIP æ–¹æ³•ï¼‰
- Mixup/CutMix æ•¸æ“šå¢å¼·
- ImageNet æ¨™æº–åŒ–é è™•ç†
- æ··åˆç²¾åº¦è¨“ç·´ (AMP)
- å­¸ç¿’ç‡èª¿åº¦å’Œæ—©åœæ©Ÿåˆ¶

ä½¿ç”¨æ–¹å¼:
    python -m src.train
    python -m src.train --config config.json
    python -m src.train --model efficientnet_b0  # å¿«é€Ÿæ¸¬è©¦
    python -m src.train --freeze-backbone        # å‡çµ backbone
"""

import argparse
import json
import os
import random
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Tuple, Optional

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, random_split
from torchvision import transforms
from PIL import Image
from tqdm import tqdm

from .models import create_model, create_model_from_config, list_available_models


# ============== Mixup / CutMix ==============

def mixup_data(x, y, alpha=0.4):
    """Mixup: æ··åˆå…©å€‹æ¨£æœ¬çš„åœ–åƒå’Œæ¨™ç±¤"""
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1.0
    
    batch_size = x.size(0)
    index = torch.randperm(batch_size).to(x.device)
    
    mixed_x = lam * x + (1 - lam) * x[index]
    y_a, y_b = y, y[index]
    
    return mixed_x, y_a, y_b, lam


def cutmix_data(x, y, alpha=1.0):
    """CutMix: å°‡ä¸€å€‹æ¨£æœ¬çš„å€åŸŸè²¼åˆ°å¦ä¸€å€‹æ¨£æœ¬ä¸Š"""
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1.0
    
    batch_size = x.size(0)
    index = torch.randperm(batch_size).to(x.device)
    
    # è¨ˆç®—è£åˆ‡å€åŸŸ
    W, H = x.size(2), x.size(3)
    cut_rat = np.sqrt(1.0 - lam)
    cut_w = int(W * cut_rat)
    cut_h = int(H * cut_rat)
    
    cx = np.random.randint(W)
    cy = np.random.randint(H)
    
    bbx1 = np.clip(cx - cut_w // 2, 0, W)
    bby1 = np.clip(cy - cut_h // 2, 0, H)
    bbx2 = np.clip(cx + cut_w // 2, 0, W)
    bby2 = np.clip(cy + cut_h // 2, 0, H)
    
    mixed_x = x.clone()
    mixed_x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]
    
    # èª¿æ•´ lambda ä»¥åæ˜ å¯¦éš›å€åŸŸæ¯”ä¾‹
    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))
    y_a, y_b = y, y[index]
    
    return mixed_x, y_a, y_b, lam


def mixup_criterion(criterion, pred, y_a, y_b, lam):
    """Mixup/CutMix çš„æå¤±è¨ˆç®—"""
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)


class DeepfakeDataset(Dataset):
    """Deepfake æª¢æ¸¬æ•¸æ“šé›†"""
    
    def __init__(self, data_dir: str, transform=None):
        self.transform = transform
        self.samples = []
        
        # è¼‰å…¥ fake åœ–åƒ (label=0)
        fake_dir = os.path.join(data_dir, 'fake')
        if os.path.exists(fake_dir):
            for f in os.listdir(fake_dir):
                if f.lower().endswith(('.jpg', '.png', '.jpeg')):
                    self.samples.append((os.path.join(fake_dir, f), 0))
        
        # è¼‰å…¥ real åœ–åƒ (label=1)
        real_dir = os.path.join(data_dir, 'real')
        if os.path.exists(real_dir):
            for f in os.listdir(real_dir):
                if f.lower().endswith(('.jpg', '.png', '.jpeg')):
                    self.samples.append((os.path.join(real_dir, f), 1))
        
        random.shuffle(self.samples)
        print(f"Loaded {len(self.samples)} samples from {data_dir}")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        path, label = self.samples[idx]
        image = Image.open(path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        return image, label


def set_seed(seed: int = 42):
    """è¨­ç½®éš¨æ©Ÿç¨®å­ä»¥ç¢ºä¿å¯é‡ç¾æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def load_config(config_path: str) -> dict:
    """è¼‰å…¥é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def get_transforms(config: dict, model=None, is_train: bool = True):
    """
    ç²å–æ•¸æ“šè½‰æ›
    
    ä½¿ç”¨ ImageNet æ¨™æº–åŒ–åƒæ•¸ï¼Œé…åˆé è¨“ç·´æ¨¡å‹ã€‚
    
    Args:
        config: é…ç½®å­—å…¸
        model: æ¨¡å‹å¯¦ä¾‹ï¼ˆç”¨æ–¼ç²å–é è™•ç†åƒæ•¸ï¼‰
        is_train: æ˜¯å¦ç‚ºè¨“ç·´æ¨¡å¼
    """
    size = config['data']['image_size']
    
    # ç²å–æ¨™æº–åŒ–åƒæ•¸
    preprocess_config = config.get('preprocessing', {})
    if preprocess_config.get('use_model_default', True) and model is not None:
        model_preprocess = model.get_preprocessing_config()
        mean = model_preprocess['mean']
        std = model_preprocess['std']
    else:
        normalize_cfg = preprocess_config.get('normalize', {})
        mean = normalize_cfg.get('mean', [0.485, 0.456, 0.406])
        std = normalize_cfg.get('std', [0.229, 0.224, 0.225])
    
    if is_train:
        aug_cfg = config['augmentation']['train']
        transform_list = []
        
        # éš¨æ©Ÿè£åˆ‡
        if 'random_crop_scale' in aug_cfg:
            scale = aug_cfg['random_crop_scale']
            transform_list.append(
                transforms.RandomResizedCrop(size, scale=tuple(scale), ratio=(0.9, 1.1))
            )
        else:
            transform_list.append(transforms.Resize((size, size)))
        
        # æ°´å¹³ç¿»è½‰
        if aug_cfg.get('horizontal_flip', 0) > 0:
            transform_list.append(transforms.RandomHorizontalFlip(aug_cfg['horizontal_flip']))
        
        # å‚ç›´ç¿»è½‰
        if aug_cfg.get('vertical_flip', 0) > 0:
            transform_list.append(transforms.RandomVerticalFlip(aug_cfg['vertical_flip']))
        
        # æ—‹è½‰
        rotation = aug_cfg.get('rotation_degrees', 0)
        if rotation > 0:
            transform_list.append(transforms.RandomRotation(rotation))
        
        # é¡è‰²æŠ–å‹•
        brightness = aug_cfg.get('brightness', 0)
        contrast = aug_cfg.get('contrast', 0)
        saturation = aug_cfg.get('saturation', 0)
        hue = aug_cfg.get('hue', 0)
        if any([brightness, contrast, saturation, hue]):
            transform_list.append(
                transforms.ColorJitter(brightness, contrast, saturation, hue)
            )
        
        # è½‰ç‚º Tensor ä¸¦æ¨™æº–åŒ–
        transform_list.append(transforms.ToTensor())
        transform_list.append(transforms.Normalize(mean=mean, std=std))
        
        # Random Erasing
        random_erasing = aug_cfg.get('random_erasing', 0)
        if random_erasing > 0:
            transform_list.append(transforms.RandomErasing(p=random_erasing))
        
    else:
        transform_list = [
            transforms.Resize((size, size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std),
        ]
    
    return transforms.Compose(transform_list)


class EarlyStopping:
    """æ—©åœæ©Ÿåˆ¶"""
    
    def __init__(self, patience: int = 7, min_delta: float = 0.0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_score = None
        self.early_stop = False
    
    def __call__(self, val_score: float) -> bool:
        if self.best_score is None:
            self.best_score = val_score
        elif val_score < self.best_score + self.min_delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = val_score
            self.counter = 0
        return self.early_stop


def train_one_epoch(
    model: nn.Module,
    loader: DataLoader,
    criterion: nn.Module,
    optimizer: optim.Optimizer,
    device: torch.device,
    epoch: int,
    scaler=None,
    gradient_clip: float = 0.0,
    scheduler=None,
    step_each_batch: bool = False,
    mixup_alpha: float = 0.0,
    cutmix_alpha: float = 0.0,
    mix_prob: float = 0.5
) -> Tuple[float, float]:
    """
    è¨“ç·´ä¸€å€‹ epoch
    
    Args:
        scheduler: å­¸ç¿’ç‡èª¿åº¦å™¨ï¼ˆç”¨æ–¼ OneCycleLRï¼‰
        step_each_batch: æ˜¯å¦æ¯å€‹ batch éƒ½æ›´æ–°å­¸ç¿’ç‡
        mixup_alpha: Mixup çš„ alpha åƒæ•¸ï¼ˆ0 è¡¨ç¤ºä¸ä½¿ç”¨ï¼‰
        cutmix_alpha: CutMix çš„ alpha åƒæ•¸ï¼ˆ0 è¡¨ç¤ºä¸ä½¿ç”¨ï¼‰
        mix_prob: ä½¿ç”¨ Mixup/CutMix çš„æ©Ÿç‡
    
    Returns:
        avg_loss, accuracy
    """
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    use_mix = mixup_alpha > 0 or cutmix_alpha > 0
    
    pbar = tqdm(loader, desc=f"Epoch {epoch} [Train]", leave=False)
    for images, labels in pbar:
        images, labels = images.to(device), labels.to(device)
        
        # æ±ºå®šæ˜¯å¦ä½¿ç”¨ Mixup/CutMix
        do_mix = use_mix and (np.random.random() < mix_prob)
        
        if do_mix:
            # éš¨æ©Ÿé¸æ“‡ Mixup æˆ– CutMix
            if cutmix_alpha > 0 and (mixup_alpha == 0 or np.random.random() > 0.5):
                images, labels_a, labels_b, lam = cutmix_data(images, labels, cutmix_alpha)
            else:
                images, labels_a, labels_b, lam = mixup_data(images, labels, mixup_alpha)
        
        optimizer.zero_grad()
        
        # æ··åˆç²¾åº¦è¨“ç·´
        if scaler is not None:
            with torch.amp.autocast(device_type='cuda', dtype=torch.float16):
                outputs = model(images)
                if do_mix:
                    loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)
                else:
                    loss = criterion(outputs, labels)
            scaler.scale(loss).backward()
            
            if gradient_clip > 0:
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)
            
            scaler.step(optimizer)
            scaler.update()
        else:
            outputs = model(images)
            if do_mix:
                loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)
            else:
                loss = criterion(outputs, labels)
            loss.backward()
            
            if gradient_clip > 0:
                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)
            
            optimizer.step()
        
        # OneCycleLR æ¯å€‹ batch æ›´æ–°å­¸ç¿’ç‡
        if step_each_batch and scheduler is not None:
            scheduler.step()
        
        running_loss += loss.item() * images.size(0)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        
        # é¡¯ç¤ºç•¶å‰å­¸ç¿’ç‡
        current_lr = optimizer.param_groups[0]['lr']
        pbar.set_postfix({
            'loss': f'{loss.item():.4f}',
            'acc': f'{100 * correct / total:.2f}%',
            'lr': f'{current_lr:.2e}'
        })
    
    avg_loss = running_loss / total
    accuracy = 100 * correct / total
    
    return avg_loss, accuracy


@torch.no_grad()
def validate(
    model: nn.Module,
    loader: DataLoader,
    criterion: nn.Module,
    device: torch.device,
    epoch: int
) -> Tuple[float, float]:
    """
    é©—è­‰æ¨¡å‹
    
    Returns:
        avg_loss, accuracy
    """
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    
    pbar = tqdm(loader, desc=f"Epoch {epoch} [Val]", leave=False)
    for images, labels in pbar:
        images, labels = images.to(device), labels.to(device)
        
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        running_loss += loss.item() * images.size(0)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        
        pbar.set_postfix({
            'loss': f'{loss.item():.4f}',
            'acc': f'{100 * correct / total:.2f}%'
        })
    
    avg_loss = running_loss / total
    accuracy = 100 * correct / total
    
    return avg_loss, accuracy


def create_optimizer(model, config: dict) -> optim.Optimizer:
    """
    å‰µå»ºå„ªåŒ–å™¨ï¼Œæ”¯æ´åˆ†å±¤å­¸ç¿’ç‡
    
    backbone ä½¿ç”¨è¼ƒå°çš„å­¸ç¿’ç‡ï¼Œclassifier ä½¿ç”¨è¼ƒå¤§çš„å­¸ç¿’ç‡
    """
    base_lr = config['training']['learning_rate']
    backbone_multiplier = config['training'].get('backbone_lr_multiplier', 0.1)
    weight_decay = config['training']['weight_decay']
    
    # æª¢æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æ´åˆ†å±¤å­¸ç¿’ç‡
    if hasattr(model, 'get_param_groups'):
        # å˜—è©¦ä½¿ç”¨æ–°çš„ APIï¼ˆDCT æ¨¡å‹ï¼‰
        import inspect
        sig = inspect.signature(model.get_param_groups)
        params = list(sig.parameters.keys())
        
        if 'base_lr' in params:
            # DCT æ¨¡å‹ä½¿ç”¨ base_lr å’Œ backbone_lr_scale
            param_groups = model.get_param_groups(
                base_lr=base_lr,
                backbone_lr_scale=backbone_multiplier
            )
        else:
            # æ¨™æº– API
            param_groups = model.get_param_groups(
                backbone_lr=base_lr * backbone_multiplier,
                classifier_lr=base_lr
            )
        
        print(f"Using layered learning rates:")
        for pg in param_groups:
            name = pg.get('name', 'unnamed')
            lr = pg.get('lr', base_lr)
            print(f"  {name}: {lr:.2e}")
    else:
        param_groups = model.parameters()
        print(f"Using uniform learning rate: {base_lr:.2e}")
    
    optimizer = optim.AdamW(
        param_groups,
        lr=base_lr,  # é€™å€‹æœƒè¢« param_groups è¦†è“‹
        weight_decay=weight_decay,
        betas=tuple(config['optimizer']['betas']),
        eps=config['optimizer']['eps']
    )
    
    return optimizer


def main():
    parser = argparse.ArgumentParser(
        description='Multi-Model Training Script for Deepfake Detection'
    )
    parser.add_argument(
        '--config', type=str, default='config.json',
        help='é…ç½®æ–‡ä»¶è·¯å¾‘'
    )
    parser.add_argument(
        '--model', type=str, default=None,
        help=f'æ¨¡å‹åç¨±ï¼ˆè¦†è“‹é…ç½®æ–‡ä»¶ï¼‰ã€‚å¯é¸: {list_available_models()}'
    )
    parser.add_argument(
        '--resume', type=str, default=None,
        help='æ¢å¾©è¨“ç·´çš„æª¢æŸ¥é»è·¯å¾‘'
    )
    parser.add_argument(
        '--epochs', type=int, default=None,
        help='è¨“ç·´ epochsï¼ˆè¦†è“‹é…ç½®æ–‡ä»¶ï¼‰'
    )
    parser.add_argument(
        '--batch-size', type=int, default=None,
        help='Batch sizeï¼ˆè¦†è“‹é…ç½®æ–‡ä»¶ï¼‰'
    )
    parser.add_argument(
        '--lr', type=float, default=None,
        help='å­¸ç¿’ç‡ï¼ˆè¦†è“‹é…ç½®æ–‡ä»¶ï¼‰'
    )
    parser.add_argument(
        '--freeze-backbone', action='store_true',
        help='å‡çµ backboneï¼Œåªè¨“ç·´åˆ†é¡å™¨ï¼ˆé¡ä¼¼ CLIP æ–¹æ³•ï¼‰'
    )
    
    args = parser.parse_args()
    
    # è¼‰å…¥é…ç½®
    config = load_config(args.config)
    
    # å‘½ä»¤è¡Œåƒæ•¸è¦†è“‹æ¨¡å‹åç¨±ï¼ˆéœ€è¦å…ˆè™•ç†ï¼Œæ‰èƒ½åˆ¤æ–·æ¨¡å‹é¡å‹ï¼‰
    if args.model:
        config['model']['name'] = args.model
    
    # æ ¹æ“šæ¨¡å‹é¡å‹é¸æ“‡å°æ‡‰çš„è¨“ç·´åƒæ•¸
    model_name = config['model']['name']
    is_clip_model = model_name.startswith('clip_')
    
    if is_clip_model:
        # ä½¿ç”¨ CLIP å°ˆç”¨åƒæ•¸ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'training_clip' in config:
            print(f"[Info] Detected CLIP model: {model_name}")
            print(f"[Info] Using CLIP-specific training parameters")
            # åˆä½µ CLIP åƒæ•¸ï¼ˆCLIP åƒæ•¸è¦†è“‹é è¨­åƒæ•¸ï¼‰
            for key, value in config['training_clip'].items():
                if not key.startswith('_'):  # è·³éè¨»è§£
                    config['training'][key] = value
        
        if 'scheduler_clip' in config:
            print(f"[Info] Using CLIP-specific scheduler parameters")
            for key, value in config['scheduler_clip'].items():
                if not key.startswith('_'):
                    config['scheduler'][key] = value
    
    # å…¶ä»–å‘½ä»¤è¡Œåƒæ•¸è¦†è“‹
    if args.epochs:
        config['training']['epochs'] = args.epochs
    if args.batch_size:
        config['training']['batch_size'] = args.batch_size
    if args.lr:
        config['training']['learning_rate'] = args.lr
    if args.freeze_backbone:
        config['training']['freeze_backbone'] = True
    
    print("=" * 60)
    print(f"Project: {config['project']['name']} v{config['project']['version']}")
    print(f"Config: {args.config}")
    print("=" * 60)
    
    # è¨­ç½®éš¨æ©Ÿç¨®å­
    set_seed(config['training']['seed'])
    
    # è¨­ç½®è¨­å‚™
    device_name = config.get('hardware', {}).get('device', 'cuda')
    if device_name == 'cuda' and torch.cuda.is_available():
        device = torch.device('cuda')
        print(f"Device: {torch.cuda.get_device_name(0)}")
        print(f"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    elif device_name == 'mps' and torch.backends.mps.is_available():
        device = torch.device('mps')
        print("Device: Apple Silicon GPU (MPS)")
    else:
        device = torch.device('cpu')
        print("Device: CPU")
    
    # æ··åˆç²¾åº¦è¨“ç·´
    use_amp = config.get('hardware', {}).get('mixed_precision', False) and device.type == 'cuda'
    scaler = torch.cuda.amp.GradScaler() if use_amp else None
    print(f"Mixed Precision: {'Enabled' if use_amp else 'Disabled'}")
    
    # åˆå§‹åŒ–æ¨¡å‹ï¼ˆå…ˆåˆå§‹åŒ–ï¼Œæ‰èƒ½çŸ¥é“æ¨¡å‹åç¨±ï¼‰
    print("\n" + "-" * 40)
    print("Initializing Model...")
    model = create_model_from_config(config)
    model = model.to(device)
    
    # æ¨¡å‹ä¿¡æ¯
    model_name = config['model'].get('name', 'unknown')
    total_params = model.count_parameters(trainable_only=False)
    trainable_params = model.count_parameters(trainable_only=True)
    print(f"Model: {model_name}")
    print(f"Total Parameters: {total_params:,} ({total_params/1e6:.2f}M)")
    print(f"Trainable Parameters: {trainable_params:,} ({trainable_params/1e6:.2f}M)")
    
    # å‰µå»ºæ¨¡å‹å°ˆå±¬è¼¸å‡ºç›®éŒ„
    base_output_dir = Path(config['output']['output_dir'])
    output_dir = base_output_dir / model_name
    output_dir.mkdir(parents=True, exist_ok=True)
    
    log_dir = Path(config['logging']['log_dir']) / model_name
    log_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"Output directory: {output_dir}")
    print(f"Log directory: {log_dir}")
    
    # å‡çµ backboneï¼ˆé¡ä¼¼ CLIP æ–¹æ³•ï¼‰
    freeze_backbone = config['training'].get('freeze_backbone', False)
    if freeze_backbone:
        print("ğŸ”’ Freezing backbone (CLIP-style training)")
        if hasattr(model, 'freeze_backbone'):
            model.freeze_backbone()
        elif hasattr(model, 'backbone'):
            for param in model.backbone.parameters():
                param.requires_grad = False
        else:
            print("  Warning: Model does not have a 'backbone' attribute")
    
    # ç²å–æ•¸æ“šè½‰æ›ï¼ˆä½¿ç”¨æ¨¡å‹çš„é è™•ç†é…ç½®ï¼‰
    train_transform = get_transforms(config, model=model, is_train=True)
    val_transform = get_transforms(config, model=model, is_train=False)
    
    # è¼‰å…¥æ•¸æ“š
    print("\n" + "-" * 40)
    print("Loading Data...")
    train_dir = os.path.join(config['data']['data_path'], 'train')
    full_dataset = DeepfakeDataset(train_dir, transform=train_transform)
    
    # åˆ†å‰²è¨“ç·´é›†å’Œé©—è­‰é›†
    val_split = config['data']['val_split']
    val_size = int(len(full_dataset) * val_split)
    train_size = len(full_dataset) - val_size
    
    train_dataset, val_dataset = random_split(
        full_dataset, 
        [train_size, val_size],
        generator=torch.Generator().manual_seed(config['training']['seed'])
    )
    
    # ç‚ºé©—è­‰é›†æ›´æ› transform
    class TransformDataset:
        def __init__(self, dataset, transform):
            self.dataset = dataset
            self.transform = transform
        def __len__(self):
            return len(self.dataset)
        def __getitem__(self, idx):
            image, label = self.dataset.dataset.samples[self.dataset.indices[idx]]
            image = Image.open(image).convert('RGB')
            if self.transform:
                image = self.transform(image)
            return image, label
    
    val_dataset_transformed = TransformDataset(val_dataset, val_transform)
    
    print(f"Training samples: {len(train_dataset)}")
    print(f"Validation samples: {len(val_dataset)}")
    print(f"Image size: {config['data']['image_size']}x{config['data']['image_size']}")
    
    # å‰µå»ºæ•¸æ“šè¼‰å…¥å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['training']['batch_size'],
        shuffle=True,
        num_workers=config['data']['num_workers'],
        pin_memory=True,
        drop_last=True
    )
    
    val_loader = DataLoader(
        val_dataset_transformed,
        batch_size=config['training']['batch_size'],
        shuffle=False,
        num_workers=config['data']['num_workers'],
        pin_memory=True
    )
    
    # æå¤±å‡½æ•¸
    label_smoothing = config['training'].get('label_smoothing', 0.0)
    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)
    
    # å„ªåŒ–å™¨ï¼ˆæ”¯æ´åˆ†å±¤å­¸ç¿’ç‡ï¼‰
    print("\n" + "-" * 40)
    print("Setting up Optimizer...")
    optimizer = create_optimizer(model, config)
    
    # è¨ˆç®—æ¯å€‹ epoch çš„æ­¥æ•¸ï¼ˆç”¨æ–¼ OneCycleLRï¼‰
    steps_per_epoch = len(train_loader)
    total_steps = steps_per_epoch * config['training']['epochs']
    
    # å­¸ç¿’ç‡èª¿åº¦å™¨
    scheduler_type = config['scheduler']['type']
    step_each_batch = False  # æ˜¯å¦æ¯å€‹ batch æ›´æ–°ä¸€æ¬¡
    step_with_metrics = False  # æ˜¯å¦éœ€è¦å‚³å…¥ metrics ä¾† step
    
    if scheduler_type == 'OneCycleLR':
        # OneCycleLRï¼šæ¯å€‹ batch éƒ½è¦ step
        scheduler = optim.lr_scheduler.OneCycleLR(
            optimizer,
            max_lr=config['scheduler'].get('max_lr', config['training']['learning_rate']),
            total_steps=total_steps,
            pct_start=config['scheduler'].get('pct_start', 0.1),
            anneal_strategy=config['scheduler'].get('anneal_strategy', 'cos'),
            div_factor=config['scheduler'].get('div_factor', 25),
            final_div_factor=config['scheduler'].get('final_div_factor', 1000),
        )
        step_each_batch = True
        print(f"Scheduler: {scheduler_type} (step per batch)")
        print(f"  Max LR: {config['scheduler'].get('max_lr', config['training']['learning_rate']):.2e}")
        print(f"  Total steps: {total_steps}")
    elif scheduler_type == 'ReduceLROnPlateau':
        # ReduceLROnPlateauï¼šæ ¹æ“šé©—è­‰æŒ‡æ¨™è‡ªé©æ‡‰èª¿æ•´
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            optimizer,
            mode=config['scheduler'].get('mode', 'max'),  # 'max' for accuracy, 'min' for loss
            factor=config['scheduler'].get('factor', 0.5),
            patience=config['scheduler'].get('patience', 3),
            min_lr=config['scheduler'].get('min_lr', 1e-6),
            threshold=config['scheduler'].get('threshold', 0.001)
        )
        step_with_metrics = True
        print(f"Scheduler: {scheduler_type}")
        print(f"  Mode: {config['scheduler'].get('mode', 'max')}")
        print(f"  Factor: {config['scheduler'].get('factor', 0.5)}")
        print(f"  Patience: {config['scheduler'].get('patience', 3)}")
        print(f"  Min LR: {config['scheduler'].get('min_lr', 1e-6):.2e}")
    elif scheduler_type == 'CosineAnnealingLR':
        scheduler = optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=config['scheduler']['T_max'],
            eta_min=config['scheduler']['eta_min']
        )
        print(f"Scheduler: {scheduler_type}")
    elif scheduler_type == 'CosineAnnealingWarmRestarts':
        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
            optimizer,
            T_0=config['scheduler']['T_0'],
            T_mult=config['scheduler'].get('T_mult', 1),
            eta_min=config['scheduler']['eta_min']
        )
        print(f"Scheduler: {scheduler_type}")
    else:
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
        print(f"Scheduler: StepLR (default)")
    
    # æ—©åœæ©Ÿåˆ¶
    early_stopping = EarlyStopping(
        patience=config['training']['patience'],
        min_delta=config['training']['min_delta']
    )
    
    # æ¢¯åº¦è£å‰ª
    gradient_clip = config['training'].get('gradient_clip', 0.0)
    
    # æ¢å¾©è¨“ç·´
    start_epoch = 0
    best_val_acc = 0.0
    
    if args.resume:
        print(f"\nResuming from: {args.resume}")
        checkpoint = torch.load(args.resume, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        if 'scheduler_state_dict' in checkpoint:
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        start_epoch = checkpoint['epoch'] + 1
        best_val_acc = checkpoint.get('best_val_acc', 0)
        print(f"Resumed from epoch {start_epoch}, best val acc: {best_val_acc:.2f}%")
    
    # è¨“ç·´è¨˜éŒ„
    history = {
        'model_name': model_name,
        'config': {
            'batch_size': config['training']['batch_size'],
            'learning_rate': config['training']['learning_rate'],
            'image_size': config['data']['image_size'],
        },
        'epochs': []
    }
    
    # æ—¥èªŒæ–‡ä»¶è·¯å¾‘ï¼ˆå¯¦æ™‚å¯«å…¥ï¼‰
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = log_dir / f"training_log_{model_name}_{timestamp}.txt"
    history_file = log_dir / f"history_{model_name}_{timestamp}.json"
    
    def write_log(message: str, also_print: bool = True):
        """å¯«å…¥æ—¥èªŒæ–‡ä»¶ä¸¦å¯é¸æ‰“å°"""
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(message + '\n')
        if also_print:
            print(message)
    
    def save_history():
        """ä¿å­˜è¨“ç·´æ­·å²åˆ° JSON"""
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, indent=2, ensure_ascii=False)
    
    # é–‹å§‹è¨“ç·´
    header = "\n" + "=" * 60 + "\n"
    header += "Starting Training\n"
    header += f"  Model: {model_name}\n"
    header += f"  Epochs: {config['training']['epochs']}\n"
    header += f"  Batch size: {config['training']['batch_size']}\n"
    header += f"  Learning rate: {config['training']['learning_rate']}\n"
    header += f"  Label smoothing: {label_smoothing}\n"
    header += f"  Scheduler: {scheduler_type}\n"
    # Mixup/CutMix é…ç½®
    aug_config = config.get('augmentation', {}).get('train', {})
    mixup_alpha = aug_config.get('mixup_alpha', 0.0)
    cutmix_alpha = aug_config.get('cutmix_alpha', 0.0)
    mix_prob = aug_config.get('mix_prob', 0.5)
    
    if mixup_alpha > 0 or cutmix_alpha > 0:
        print(f"Mixup/CutMix: mixup_alpha={mixup_alpha}, cutmix_alpha={cutmix_alpha}, prob={mix_prob}")
    
    header += "=" * 60 + "\n"
    write_log(header)
    
    start_time = time.time()
    
    for epoch in range(start_epoch, config['training']['epochs']):
        epoch_start = time.time()
        
        # è¨“ç·´ï¼ˆå‚³å…¥ scheduler ç”¨æ–¼ OneCycleLRï¼Œå‚³å…¥ mixup/cutmix åƒæ•¸ï¼‰
        train_loss, train_acc = train_one_epoch(
            model, train_loader, criterion, optimizer, device,
            epoch + 1, scaler=scaler, gradient_clip=gradient_clip,
            scheduler=scheduler, step_each_batch=step_each_batch,
            mixup_alpha=mixup_alpha, cutmix_alpha=cutmix_alpha, mix_prob=mix_prob
        )
        
        # é©—è­‰
        val_loss, val_acc = validate(
            model, val_loader, criterion, device, epoch + 1
        )
        
        # æ›´æ–°å­¸ç¿’ç‡ï¼ˆæ ¹æ“š scheduler é¡å‹ï¼‰
        current_lr = optimizer.param_groups[0]['lr']
        if step_with_metrics:
            # ReduceLROnPlateau éœ€è¦å‚³å…¥ metric
            scheduler.step(val_acc)
        elif not step_each_batch:
            # å…¶ä»– epoch-based scheduler
            scheduler.step()
        
        epoch_time = time.time() - epoch_start
        
        # è¨˜éŒ„æœ¬ epoch çµæœ
        epoch_result = {
            'epoch': epoch + 1,
            'train_loss': round(train_loss, 4),
            'train_acc': round(train_acc, 2),
            'val_loss': round(val_loss, 4),
            'val_acc': round(val_acc, 2),
            'lr': current_lr,
            'time': round(epoch_time, 1)
        }
        history['epochs'].append(epoch_result)
        
        # æ§‹å»ºæ—¥èªŒè¡Œ
        is_best = val_acc > best_val_acc
        log_line = (f"Epoch {epoch + 1:3d}/{config['training']['epochs']} | "
                    f"Train: {train_acc:.2f}% ({train_loss:.4f}) | "
                    f"Val: {val_acc:.2f}% ({val_loss:.4f}) | "
                    f"LR: {current_lr:.2e} | "
                    f"Time: {epoch_time:.1f}s")
        
        if is_best:
            log_line += " | â˜… Best!"
        
        # å¯«å…¥æ—¥èªŒä¸¦æ‰“å°
        write_log(log_line)
        
        # å³æ™‚ä¿å­˜è¨“ç·´æ­·å²ï¼ˆæ¯å€‹ epoch éƒ½å­˜ï¼‰
        save_history()
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            best_val_acc = val_acc
            torch.save({
                'epoch': epoch,
                'model_name': model_name,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'best_val_acc': best_val_acc,
                'config': config
            }, output_dir / 'best_model.pth')
        
        # å®šæœŸä¿å­˜æª¢æŸ¥é»
        checkpoint_interval = config['logging'].get('checkpoint_interval', 5)
        if (epoch + 1) % checkpoint_interval == 0:
            torch.save({
                'epoch': epoch,
                'model_name': model_name,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'best_val_acc': best_val_acc,
                'config': config
            }, output_dir / 'latest_checkpoint.pth')
        
        # æ—©åœæª¢æŸ¥
        if early_stopping(val_acc):
            write_log(f"\nâš  Early stopping triggered at epoch {epoch + 1}")
            break
    
    # æœ€çµ‚æ‘˜è¦
    history['summary'] = {
        'best_val_acc': round(best_val_acc, 2),
        'total_epochs': len(history['epochs']),
        'total_time_minutes': round((time.time() - start_time) / 60, 2)
    }
    save_history()
    
    # è¨“ç·´å®Œæˆ
    total_time = time.time() - start_time
    
    summary = "\n" + "=" * 60 + "\n"
    summary += "Training Complete!\n"
    summary += f"  Model: {model_name}\n"
    summary += f"  Total Time: {total_time / 60:.2f} minutes\n"
    summary += f"  Best Validation Accuracy: {best_val_acc:.2f}%\n"
    summary += f"  Best model: {output_dir / 'best_model.pth'}\n"
    summary += f"  Training log: {log_file}\n"
    summary += f"  History JSON: {history_file}\n"
    summary += "=" * 60
    write_log(summary)


if __name__ == "__main__":
    main()
